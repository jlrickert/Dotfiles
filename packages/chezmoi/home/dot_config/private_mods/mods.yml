# Default model (gpt-3.5-turbo, gpt-4, ggml-gpt4all-j...).
default-model: gpt-4o-mini
# default-model: qwen2.5-coder-32b-instruct
# Text to append when using the -f flag.
format-text:
  markdown: "Format the response as markdown without enclosing backticks."
  json: "Format the response as json without enclosing backticks."
# Ask for the response to be formatted as markdown unless otherwise set.
format: false
# Render output as raw text when connected to a TTY.
raw: false
# Quiet mode (hide the spinner while loading and stderr messages for success).
quiet: false
# Temperature (randomness) of results, from 0.0 to 2.0.
temp: 1.0
# TopP, an alternative to temperature that narrows response, from 0.0 to 1.0.
topp: 1.0
# Turn off the client-side limit on the size of the input into the model.
no-limit: true
# Wrap formatted output at specific width (default is 80)
word-wrap: 80
# Include the prompt from the arguments in the response.
include-prompt-args: false
# Include the prompt from the arguments and stdin, truncate stdin to specified number of lines.
include-prompt: 0
# Maximum number of times to retry API calls.
max-retries: 5
# Your desired level of fanciness.
fanciness: 10
# Text to show while generating.
status-text: Generating
# Default character limit on input to model.
max-input-chars: 12250
# Maximum number of tokens in response.
# max-tokens: 100
roles:
  mdformat:
    - you are to format the given input
    - users only care about the output
    - output is to be in markdown only
  shell:
    - you are a shell expert
    - you do not explain anything
    - you simply output one liners to solve the problems you're asked
    - you do not provide any explanation whatsoever, ONLY the command
  code:
    - you are an expert programmer
    - you do not explain anything
    - you simply output the most appropriate code
    - do add document blocks if appropriate
    - output is to be code only. No markdown output
  keg:
    - you are an inport bot for a data in the KEG format
    - you don't need to respond back when I am giving you information about a node
    - you need to reference where you got your information
  keg-assistant:
    - you are a helpful assistance.
    - you are to help users find the documents that contain the information they are looking for
    - you must reference the document you are summarizing from
  bash-script:
    - you are a professional bash programmer
    - you do not provide any explanation whatsoever, ONLY the code
    - follow googles bash style guide
    - avoid ignore shellcheck warnings when possible
  bash:
    - you are world class bash programmer
    - you are to give a very detail explanation on why this would be the best approach
    - yar are to follow googles shell style guide as much as possible
    - shebangs should use `#!/usr/bin/env bash` because I use macosx
    - avoid ignore shellcheck warnings when possible
  go:
    - you are a go expert
  go-lsp:
    - you are a go expert
    - you do not explain anything
    - you do not provide any explanation whatsoever, ONLY the code
  php:
    - you are world class php programmer
    - you are to give a very detail explanation on why this would be the best approach
    - multiple approaches to the solution is also encourged
    - users prefer responses in markdown
  ecw:
    - you are a professional developer at Ecreativeworks
  typescript:
    - you are world class typescript programmer
    - you are to give a very detail explanation on why this would be the best approach
    - multiple approaches to the solution is also encourged
    - users prefer responses in markdown
# Aliases and endpoints for OpenAI compatible REST API.
apis:
  openai:
    base-url: https://api.openai.com/v1
    api-key:
    api-key-env: OPENAI_API_KEY
    models:
      gpt-4o-mini:
        max-input-chars: 392000
        fallback: gpt-4o
      gpt-4o:
        aliases: ["4o"]
        max-input-chars: 392000
        fallback: gpt-4o-mini
      gpt-4:
        aliases: ["4"]
        max-input-chars: 24500
        fallback: gpt-3.5-turbo
      gpt-4-1106-preview:
        aliases: ["128k"]
        max-input-chars: 392000
        fallback: gpt-4
      gpt-4-32k:
        aliases: ["32k"]
        max-input-chars: 98000
        fallback: gpt-4
      gpt-3.5-turbo:
        aliases: ["35t"]
        max-input-chars: 12250
        fallback: gpt-3.5
      gpt-3.5-turbo-1106:
        aliases: ["35t-1106"]
        max-input-chars: 12250
        fallback: gpt-3.5-turbo
      gpt-3.5-turbo-16k:
        aliases: ["35t16k"]
        max-input-chars: 44500
        fallback: gpt-3.5
      gpt-3.5:
        aliases: ["35"]
        max-input-chars: 12250
        fallback:
  localai:
    # LocalAI setup instructions: https://github.com/go-skynet/LocalAI#example-use-gpt4all-j-model
    base-url: http://localhost:8080
    models:
      qwen2.5-coder-32b-instruct:
        aliases: ["gwen32b"]
        max-input-chars: 12800
        fallback:
      qwen2.5-coder-3b-instruct:
        aliases: ["gwen3b"]
      qwen2.5-72b-instruct:
        aliases: ["gwen"]
      ggml-gpt4all-j:
        aliases: ["local", "4all"]
        max-input-chars: 12250
        fallback:
  azure:
    # Set to 'azure-ad' to use Active Directory
    # Azure OpenAI setup: https://learn.microsoft.com/en-us/azure/cognitive-services/openai/how-to/create-resource
    base-url: https://YOUR_RESOURCE_NAME.openai.azure.com
    api-key:
    api-key-env: AZURE_OPENAI_KEY
    models:
      gpt-4:
        aliases: ["az4"]
        max-input-chars: 24500
        fallback: gpt-35-turbo
      gpt-35-turbo:
        aliases: ["az35t"]
        max-input-chars: 12250
        fallback: gpt-35
      gpt-35:
        aliases: ["az35"]
        max-input-chars: 12250
        fallback:
